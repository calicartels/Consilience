# Consilience

AI research assistant for interdisciplinary conversations with real-time transcription, intelligent trigger detection, and multi-perspective expert responses.

## Overview

Consilience monitors live academic discussions and provides timely interdisciplinary perspectives when needed. The system combines real-time speech-to-text, conversation context management, intelligent decision-making, and domain expert synthesis to assist research teams.

## Architecture

```
├── STT/              # Speech-to-Text engines (Deepgram, AssemblyAI)
├── DB/               # Storage layer (Redis + Supabase + Auth)
├── LISTENER/         # Message forwarding + trigger detection
├── CONTEXT/          # Context Builder (buffering, summarization, domain inference)
├── ORCHESTRATOR/     # Decision engine (Liaison Agent, background analysis)
├── SPECIALISTS/      # Domain expert perspective generation
├── DELIVERY/         # Delivery Monitor (priority queues, silence detection)
└── launcher.py       # System launcher
```

**STT Module**: Real-time transcription with speaker diarization (Deepgram/AssemblyAI)
**DB Module**: Hybrid Redis + Supabase storage with team authentication
**LISTENER Module**: Forwards all messages to Context Builder, detects "consilience" mentions
**CONTEXT Module**: Maintains conversation state (2-min buffer, summaries, domain inference, keywords)
**ORCHESTRATOR Module**: Intelligent decision-making via Liaison Agent (PATH A/B/C), background analysis (P1/P2/P3)
**SPECIALISTS Module**: Generates PhD→undergrad level domain perspectives (18 supported domains)
**DELIVERY Module**: Priority-based delivery with silence detection and relevance checking

## Quick Start

1. **Environment Setup**
   ```bash
   # Install system dependencies
   brew install portaudio redis
   
   # Install Python packages
   pip install -r requirements.txt
   
   # Configure environment
   cp .env.example .env
   # Edit .env with your API keys
   ```

2. **Start System**
   ```bash
   # Launch entire system with one command
   python launcher.py
   
   # Follow interactive prompts:
   # 1. Action: create (new team) or join (existing team)
   # 2. Team name
   # 3. Password
   
   # System automatically starts all modules:
   # - Storage Worker
   # - Context Builder
   # - Listener
   # - Orchestrator
   # - Delivery Monitor
   # - Deepgram STT
   
   # Start speaking - Consilience is listening!
   ```

## Data Flow

Complete message pipeline through the system:

```
1. Speech Input → Deepgram STT → Redis Storage
   ↓
2. Listener (polls Redis)
   ├─→ Forwards ALL messages to Context Builder
   └─→ Detects "consilience" mentions → Signals Orchestrator
   
3. Context Builder
   ├─→ Buffers recent messages (2-min window)
   ├─→ Summarizes older messages
   ├─→ Infers domains every 5 msgs or 30s
   ├─→ Extracts keywords per message
   └─→ Stores state to Redis
   
4. Orchestrator - Task 1 (Direct Triggers)
   ├─→ Receives signal from Listener
   ├─→ Waits 5s or 5 messages for context
   ├─→ Liaison Agent decides: PATH A (skip) / B (respond) / C (clarify)
   ├─→ If PATH B: Calls Specialists
   └─→ Queues P0 response (immediate delivery)
   
5. Orchestrator - Task 2 (Background Analysis)
   ├─→ Waits 120s startup, then checks every 90s
   ├─→ Detects factual errors → Queue P1 (30s target)
   └─→ Detects stuck signals → Queue P2/P3 (90s target)
   
6. Specialists
   ├─→ Generate perspectives from requested domains
   ├─→ PhD → undergrad communication level
   ├─→ Check Consilience history to avoid repetition
   └─→ Return formatted response
   
7. Delivery Monitor
   ├─→ Watches P0/P1/P2/P3 queues
   ├─→ Reads conversation state (silence, keywords)
   ├─→ Delivers P0 immediately
   ├─→ Delivers P1/P2/P3 during 4s silence windows
   ├─→ Checks relevance via keyword matching
   └─→ Writes consilience_spoke flag (30s expiration)
   
8. Follow-up Loop
   └─→ Listener detects consilience_spoke flag
       └─→ Tags next messages as potential_follow_up
           └─→ Orchestrator verifies semantic connection
```

## Priority System

Consilience uses a 4-level priority system for response timing:

**P0 - Immediate**:
- Direct "consilience" mentions by users
- Delivered instantly with no conditions
- Generated by: Orchestrator Task 1 (Direct Triggers)

**P1 - High Priority (30s target)**:
- Factual errors requiring correction
- Delivered during silence within 30 seconds of detection
- Generated by: Orchestrator Task 2 (Background Analysis)

**P2 - Medium Priority (90s target)**:
- Moderate stuck signals (team difficulties)
- Delivered during silence within 90 seconds of detection
- Generated by: Orchestrator Task 2 (Background Analysis)

**P3 - Low Priority (90s target)**:
- Low-priority stuck signals or missing perspectives
- Delivered during silence within 90 seconds of detection
- Generated by: Orchestrator Task 2 (Background Analysis)

All P1/P2/P3 responses wait for 4-second silence threshold and check relevance before delivery.

## Module Documentation

### [STT Documentation](STT/README-STT.md)
- Multiple transcription providers (Deepgram, AssemblyAI, OpenAI)
- Real-time speaker diarization
- WebSocket streaming implementation
- API comparison and selection guide

### [DB Documentation](DB/README-DB.md)  
- Redis + Supabase hybrid architecture
- Session-based data isolation
- Background batch processing
- Team authentication system

### [LISTENER Documentation](LISTENER/README-LISTENER.md)
- Dumb pipe forwarding to Context Builder
- LLM-based "consilience" mention detection
- Follow-up window tagging (30s)
- Signal format to Orchestrator

### [CONTEXT Documentation](CONTEXT/README-CONTEXT.md)
- 2-minute message buffering
- Rolling summarization with GPT-4o
- Domain inference (18 academic disciplines)
- Keyword extraction per message
- Silence detection for delivery timing

### [ORCHESTRATOR Documentation](ORCHESTRATOR/README-ORCHESTRATOR.md)
- Dual-task architecture (Task 1: Direct, Task 2: Background)
- Liaison Agent decision framework (PATH A/B/C)
- Follow-up verification system
- Conservative factual error detection
- Stuck signal detection
- Semantic deduplication

### [SPECIALISTS Documentation](SPECIALISTS/README-SPECIALISTS.md)
- Universal specialist prompt system
- PhD → undergraduate communication level
- 18 supported academic domains
- Parallel perspective generation
- Anti-repetition checking

## Supported Domains

Consilience can provide perspectives from 18 academic disciplines:

- Biology / Life Sciences
- Chemistry / Biochemistry
- Physics / Astronomy
- Mathematics / Statistics
- Computer Science / Software Engineering
- Medicine / Health Sciences / Neuroscience
- Psychology / Cognitive Science
- Engineering (Mechanical, Electrical, Civil, etc.)
- Business / Economics / Management
- Social Sciences / Sociology / Anthropology
- Environmental Science / Ecology
- Political Science / Law
- Philosophy / Ethics
- History / Humanities
- Linguistics / Communication
- Data Science / Machine Learning
- Design / User Experience
- Robotics / Automation

## Environment Variables

Create `.env` file with:
```
# Speech Recognition APIs (choose one)
DEEPGRAM_API_KEY=your_deepgram_key
ASSEMBLYAI_API_KEY=your_assemblyai_key

# LLM for decision-making and perspectives
OPENAI_API_KEY=your_openai_key

# Storage backends  
REDIS_HOST=localhost
REDIS_PORT=6379
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_key
```

## Requirements

- **Python 3.8+**
- **Redis Server** (for real-time message queue)
- **Audio Input Device** (microphone)
- **API Keys**:
  - Deepgram or AssemblyAI (for transcription)
  - OpenAI (for Liaison Agent, domain inference, specialists)
- **Supabase Account** (for persistent storage)

## System Control

The launcher handles all process management:

```bash
# Start system
python launcher.py

# Stop system
Press Ctrl+C (graceful shutdown of all processes)

# Manual module start (for development)
python CONTEXT/context_builder.py <session-id>
python LISTENER/listener.py <session-id>
python ORCHESTRATOR/orchestrator.py <session-id>
python DELIVERY/delivery_monitor.py <session-id>
python STT/deepgram.py <session-id>
```

## How It Works

1. **Team speaks naturally** in research discussion
2. **Deepgram transcribes** speech in real-time with speaker labels
3. **Listener forwards** all messages to Context Builder
4. **Context Builder maintains** conversation memory (summaries, domains, keywords)
5. **When user says "consilience"**:
   - Listener signals Orchestrator
   - Orchestrator waits 5s for context accumulation
   - Liaison Agent decides if response needed (PATH A/B/C)
   - If PATH B: Specialists generate domain perspectives
   - Response queued as P0 (immediate delivery)
6. **Background monitoring** (every 90s):
   - Checks for factual errors → P1 responses
   - Checks for stuck signals → P2/P3 responses
7. **Delivery Monitor** watches for silence and delivers appropriately
8. **Follow-up detection**: Next 30s tagged for follow-up verification

---

For detailed implementation, setup instructions, and API specifics, see the module-specific README files linked above.
